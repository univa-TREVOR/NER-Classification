{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "595sFrvGOKFe"
   },
   "source": [
    "# 개인정보 가명처리 모델\n",
    "> NER (Named Entity Recognition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "halBV3YJOE_t"
   },
   "source": [
    "## 작업환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U87H5oekPHj-"
   },
   "source": [
    "colab으로 생성한 노트북(.ipynb) 커널을 구글드라이브(google dirve) 경로에 마운트 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idodsVVUh2CS"
   },
   "outputs": [],
   "source": [
    "# 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-7BSSJKbEJa"
   },
   "source": [
    "작업 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqC6V02CbGPF"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/abc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcKOgJwGLlId"
   },
   "source": [
    "### datasets 라이브러리 설치\n",
    "- Hugging Face에서 제공하는 데이터셋 관리 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Sad4deKd0a7"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtHanwJcQK_q"
   },
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GLJAjGRQxQg"
   },
   "source": [
    "python의 기본 라이브러리와 함께 Hugging Face의 datasets, transformers의 라이브러리를 불러 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSOB1U3PeDuJ"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os, glob, json, random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForTokenClassification,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,\n",
    "                          DataCollatorWithPadding)\n",
    "\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpG8-2lxhndP"
   },
   "outputs": [],
   "source": [
    "login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6kuVaOOQb-h"
   },
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHEgXptVQegf"
   },
   "source": [
    "### 데이터셋 로드\n",
    "- huggin face 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPhpd3J9eEV8"
   },
   "outputs": [],
   "source": [
    "merge_ds=datasets.load_dataset('TeamUNIVA/NER_example')['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ4nz71xSBmF"
   },
   "source": [
    "### 개인정보 식별자 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ypz4TMXSoRm"
   },
   "source": [
    "데이터(text)에서 식별자 형식(`{개인정보}`)으로 포함된 개인정보를 추출합니다.\n",
    "- 정규표현식을 사용하여 개인정보 식별자를 추출\n",
    "- 추출된 개인정보 식별자는 리스트(list)로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_co6nP8g6sn"
   },
   "outputs": [],
   "source": [
    "refine_ds = []\n",
    "\n",
    "for item in merge_ds:\n",
    "\n",
    "    x = item\n",
    "\n",
    "    # 중괄호로 감싸진 식별자를 추출하는 코드 | 정규표현식\n",
    "    id_list = re.findall(r'\\{.*?\\}',x['assistant'])\n",
    "\n",
    "    x['id_list'] = id_list\n",
    "\n",
    "    refine_ds.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1heAO3tATFWR"
   },
   "source": [
    "추출된 전체 개인정보 식별자를 확인\n",
    "- 정의하지 않은 개인정보 식별자 포함 여부를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NK_0M_RphuwE"
   },
   "outputs": [],
   "source": [
    "list(set(pd.DataFrame(refine_ds)['id_list'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSFTrMC-TQ7L"
   },
   "source": [
    "데이터 필터링\n",
    "- 정의하지 않은 개인정보 식별자를 포함한 데이터를 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjQwoeLfhv7U"
   },
   "outputs": [],
   "source": [
    "refine_ds = [item for item in refine_ds if '{WEIGHT}' not in item['id_list']]\n",
    "refine_ds = [item for item in refine_ds if '{AGE}' not in item['id_list']]\n",
    "refine_ds = [item for item in refine_ds if '{DRUG_NAME}' not in item['id_list']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMIlzLmgThYX"
   },
   "source": [
    "필터링된 개인정보 식별자를 correct_list로 생성\n",
    "- 이후 NER에서 Entity를 정의하고 매핑(mapping)하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CHhbiUPhxJH"
   },
   "outputs": [],
   "source": [
    "correct_list = sorted(list(set(pd.DataFrame(refine_ds)['id_list'].sum())))\n",
    "correct_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSciXWvz_XD"
   },
   "source": [
    "### 데이터 EDA\n",
    "> 데이터의 정량적인 정보를 확인\n",
    "- 텍스트 길이분포\n",
    "- 데이터별 라벨 개수\n",
    "- 식별자별 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnQHg1Jw0UfC"
   },
   "source": [
    "데이터프레임 생성 (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2tngcAc0pB8"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(refine_ds)\n",
    "# 데이터별 식별자의 수량 추가\n",
    "df['id_length'] = df['id_list'].apply(lambda X: len(X))\n",
    "\n",
    "# 텍스트 길이 추가(어절)\n",
    "df['text_len'] = df['assistant'].apply(lambda X: len(X.split(' ')))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fRbCDMs03Td"
   },
   "source": [
    "### 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVmf0x_O2GUq"
   },
   "source": [
    " 데이터별 식별자의 개수와 텍스트의 길이 분포를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW4qV3sh1AUB"
   },
   "outputs": [],
   "source": [
    "# 1 by 2 plot 생성\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 첫 번째 plot - Num ID\n",
    "axes[0].hist(df['id_length'], bins=6, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Num ID', fontsize=16, fontweight='bold')\n",
    "axes[0].set_xlabel('Num of ID', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# ytick 간격 조정\n",
    "max_frequency_id = axes[0].get_ylim()[1]\n",
    "axes[0].set_yticks(np.arange(0, max_frequency_id + 1, step=400))\n",
    "\n",
    "# 두 번째 히스토그램 - Text length\n",
    "axes[1].hist(df['text_len'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Distribution of Text Length', fontsize=16, fontweight='bold')\n",
    "axes[1].set_xlabel('Text Length', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# ytick 간격 조정\n",
    "max_frequency_text = axes[1].get_ylim()[1]\n",
    "axes[1].set_yticks(np.arange(0, max_frequency_text + 1, step=400))\n",
    "\n",
    "plt.tight_layout()  # 그래프 간격을 자동으로 조정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAgrISv52Hwo"
   },
   "source": [
    "전체 데이터이 식별자별 개수(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ApK6186Y2by3"
   },
   "outputs": [],
   "source": [
    "# 데이터프레임으로 확인\n",
    "# id_list의 합산값에 대한 빈도수를 계산\n",
    "sum_value = pd.Series(df['id_list'].sum()).value_counts()\n",
    "\n",
    "# 데이터프레임 출력\n",
    "pd.DataFrame(sum_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jqOnhsn2NNb"
   },
   "outputs": [],
   "source": [
    "# 빈도수를 막대그래프로 시각화 (bar plot)\n",
    "plt.figure(figsize=(16,6))\n",
    "sum_value.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Frequency of IDs')\n",
    "plt.xlabel('count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMXMTtIWUKnQ"
   },
   "source": [
    "### 개인정보 DB 로드\n",
    "- 난수 및 무작위 조합 방식으로 생성한 유형별 개인정보 DB\n",
    "- 각 항목별로 일부 영역이 비식별화 처리됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwXjBIM8UOmJ"
   },
   "source": [
    ".json 포맷의 개인정보 DB 파일을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyff5_4hhyWE"
   },
   "outputs": [],
   "source": [
    "with open('./private_db.json', 'r', encoding='utf-8') as f:\n",
    "    db = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PJ59BWqlq-g"
   },
   "source": [
    "### BIO 표기법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrwGKf-FluWC"
   },
   "source": [
    "BIO Entity 카테고리 생성\n",
    "- NER으로 분류하는 Entity를 BIO 표기법으로 생성\n",
    "- 분류해야하는 객체의 시작을 '`B-`', 객체의 중간과 끝을 '`I-`' 그리고 entitiy 분류되지 않는 객체는 `0`(int)로 표기\n",
    "    - B- : Begin\n",
    "    - I- : Inside\n",
    "    - O :  Outside\n",
    "- 앞에서 선언한 correct_list의 값을 for문으로 돌면서 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZdag6QNh0my"
   },
   "outputs": [],
   "source": [
    "# entitie 카테고리 생성\n",
    "\n",
    "# 선행 식별자\n",
    "bi0_list = ['I-','B-']\n",
    "\n",
    "label_list = []\n",
    "for i in range(len(bi0_list)):\n",
    "    bi0 = bi0_list[i]\n",
    "    for item in correct_list: # correct_list는 앞에서 처리한 전체 Entity 객체의 고유값\n",
    "        lb = bi0 + item[1:-1]\n",
    "\n",
    "        label_list.append(lb)\n",
    "\n",
    "# 카테고리의 가정 첫번째는 O(Outside)에 해당하는 '0'을 설정\n",
    "label_list.insert(0,'0')\n",
    "\n",
    "print(len(label_list))\n",
    "\n",
    "# 객체명의 순서의 기준 정렬을 통해 설정\n",
    "label_list.sort()\n",
    "label_list= list((label_list))\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB3bERb6nOe-"
   },
   "source": [
    "Entity index 매핑\n",
    "- index는 Entity의 순서대로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPV7M5dGh6rQ"
   },
   "outputs": [],
   "source": [
    "cat_idx_dict = {}\n",
    "for idx, cat in enumerate(label_list):\n",
    "    cat_idx_dict[cat] = idx\n",
    "cat_idx_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQrQaUv5ocR5"
   },
   "source": [
    "### 개인정보 치환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA5byQB7oixh"
   },
   "source": [
    "데이터 치환함수\n",
    "- 개인정보 DB를 입력 받아 각 개인정보 유형에 해당하는 정보를 랜덤으로 매칭함.\n",
    "- 식별자로 개인정보가 포함된 텍스트를 매칭된 개인정보에 맞춰 치환하는 방식\n",
    "- 개별 데이터와 개인정보 DB(db)를 인자로 받아 실행하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcC579Dhh76K"
   },
   "outputs": [],
   "source": [
    "def private_info_replace(x,db):\n",
    "\n",
    "    # 추출된 식별자 정보\n",
    "    ids = x['id_list']\n",
    "\n",
    "    # 텍스트에서 개인정보 치환을 위한 식별자 set 생성\n",
    "    replace_set = {}\n",
    "\n",
    "    labeling_list = []\n",
    "    labelings =[]\n",
    "    for item in ids:\n",
    "        key = item[1:-1] # 식별자의 중괄호를 파싱\n",
    "        key = key.lower() # db에서 key를 대응시키기 위해 소문자로 변환\n",
    "\n",
    "        value = random.choice(db[key]) # 식별자 키로 db에서 개인정보를 랜덤으로 매핑\n",
    "\n",
    "        replace_set[item] = value # replace_set 업데이트\n",
    "\n",
    "        labeling_dict ={\n",
    "            item:value\n",
    "        }\n",
    "        labeling_list.append(labeling_dict)\n",
    "\n",
    "    # 식별자가 포함된 텍스트를 위에서 매핑한 식별자:개인정보로 수정(replace)\n",
    "    for old, new in replace_set.items():\n",
    "        x['assistant'] = x['assistant'].replace(old, new)\n",
    "\n",
    "\n",
    "    # 수정(replace) 내역을 별토의 key로 기록\n",
    "    mapped_data = [{k: replace_set.get(k, v) for k, v in item.items()} for item in labeling_list]\n",
    "    x['keywords'] = mapped_data\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHjOKU1spZaN"
   },
   "source": [
    "개인정보 치환 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14sLY5DHh9SM"
   },
   "outputs": [],
   "source": [
    "# 함수 실행\n",
    "new_data = [private_info_replace(item,db) for item in refine_ds]\n",
    "\n",
    "# 처리된 데이터 확인\n",
    "new_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9W5GGtOrPT_"
   },
   "source": [
    "BIO 표기를 적용하기 위한 labeling_info 생성\n",
    "- 치환한 식별자:개인정보의 인덱스 값을 함께 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAd_uyNBh-RW"
   },
   "outputs": [],
   "source": [
    "for item in new_data:\n",
    "    labeling_info = []\n",
    "\n",
    "    # 인덱스 기본 값 = 0\n",
    "    start = 0\n",
    "\n",
    "    # label의 기준이 되는 텍스트 (개인정보 포함 텍스트)\n",
    "    text = item['assistant']\n",
    "\n",
    "\n",
    "    for label in item['keywords']:\n",
    "        key = list(label.keys())[0]\n",
    "        value = list(label.values())[0]\n",
    "\n",
    "        # 치환한 개인정보가 시작하는 위치값\n",
    "        start = text.find(value,start)\n",
    "\n",
    "        if start == -1:\n",
    "            break\n",
    "\n",
    "        # 치환한 개인정보가 시작하는 위치값, 시작값 + 개인정보 텍스트의 길이를 index로 설정\n",
    "        index = [start,start+len(value)]\n",
    "\n",
    "        # index 추출 순회를 위한 start값 업데이트\n",
    "        start += len(value)\n",
    "\n",
    "        data_dict ={\n",
    "            'category': key[1:-1], # 식별자의 중괄호를 파싱\n",
    "            'word':value, # 치환한 개인정보\n",
    "            'location': index # 치환한 개인정보의 위치값\n",
    "        }\n",
    "\n",
    "        labeling_info.append(data_dict)\n",
    "\n",
    "    item['labeling_info'] = labeling_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT-GvCIWtaVZ"
   },
   "source": [
    "### BIO 표기 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN-nnr0ztdo-"
   },
   "source": [
    "BIO 표기 적용 함수(string 단위)\n",
    "- 텍스트의 글자 단위로 label을 적용하고 개인정보에 해당하는 텍스트는 앞에서 설정한 Entity를 표기\n",
    "- Entity를 표기하는 텍스트의 가장 첫번째는 '`B-`', 나머지 영역을 '`I-`'로 표기\n",
    "- Entity에 해당하지 않은 텍스트(string)은 '`0`'로 표기함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYvBvk01iZYv"
   },
   "outputs": [],
   "source": [
    "def exclude_MetaText(x):\n",
    "    text = x['assistant']\n",
    "    annotations = x['labeling_info']\n",
    "\n",
    "    # BIO 표기법을 위한 레이블 초기화\n",
    "    labels = ['0'] * len(text)\n",
    "\n",
    "    # 개인정보의 위치값을 기반으로 BIO 표기\n",
    "    for annotation in annotations:\n",
    "        start,end = annotation['location']\n",
    "        category = annotation['category']\n",
    "\n",
    "        # start값이 텍스트의 길이보다 크거나 end값이 텍스트의 길이보다 길면 오류 메시지를 출력\n",
    "        if start >= len(text) or end >= len(text):\n",
    "            print('location values error')\n",
    "            continue\n",
    "\n",
    "        # start값은 'B-', 나머지 end값까지의 위치는 'I-'로 표기\n",
    "        if start == end:\n",
    "            labels[start] = f'B-{category}'\n",
    "        else:\n",
    "            labels[start] = f'B-{category}'\n",
    "\n",
    "            for i in range(start+1, end):\n",
    "                labels[i] = f'I-{category}'\n",
    "\n",
    "    x['labels'] = labels\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoxyxwC2vaMS"
   },
   "source": [
    "BIO 표기 함수 실행 & 데이터 재구조화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ai5-qmmzias0"
   },
   "outputs": [],
   "source": [
    "the_new_data = []\n",
    "\n",
    "for item in new_data:\n",
    "    result = exclude_MetaText(item) # 함수 적용\n",
    "    text = result['assistant']\n",
    "    labels = result['labels']\n",
    "\n",
    "    data_dict={\n",
    "        'text':text,\n",
    "        'labeling_info': result['labeling_info'],\n",
    "        'labels':labels\n",
    "    }\n",
    "\n",
    "    the_new_data.append(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozA6QUAnvjJo"
   },
   "source": [
    "BIO 표기 결과 확인\n",
    "- index : string : label의 순서로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0bHMz6Dib94"
   },
   "outputs": [],
   "source": [
    "idx = 67\n",
    "for i in range(len(the_new_data[idx]['text'])):\n",
    "    a = the_new_data[idx]['text'][i]\n",
    "    b = the_new_data[idx]['labels'][i]\n",
    "\n",
    "    print(f'{i}:{a}:{b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuBnNA7YwCQE"
   },
   "source": [
    "### BIO 표기 수정 (token 단위)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVBo9plhwXMP"
   },
   "source": [
    "토크나이저 로드\n",
    "- klue/roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBqKOh3eidPD"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_path = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6p5fGXaxQCm"
   },
   "source": [
    "label 정렬/수정 함수\n",
    "- string 단위로 적용된 BIO 표기를 token 단위로 수정하는 함수\n",
    "- 한글이 포함되지 않는 Entity의 오류(한글포함)오류를 수정하는 함수\n",
    "    - 정규표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXgNejvwif-2"
   },
   "outputs": [],
   "source": [
    "# BIO label을 token 단위로 수정하는 함수\n",
    "def allign_tokens(x):\n",
    "    text = x['text']\n",
    "    char_labels = x['labels']\n",
    "\n",
    "    # 텍스트 인코딩\n",
    "    encoding = tokenizer.encode_plus(text, return_offsets_mapping=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    token_indices = encoding[\"offset_mapping\"][1:-1]  # [CLS]와 [SEP]의 오프셋을 제외\n",
    "\n",
    "    # 각 토큰의 인덱스를 추출하고 인덱스에 해당하는 label(Entity)를 적용\n",
    "    token_labels = []\n",
    "    for i, (start_char, end_char) in enumerate(token_indices):\n",
    "        token_label = char_labels[start_char]\n",
    "        token_labels.append(token_label)\n",
    "\n",
    "    x['tokens'] = tokens\n",
    "    x['token_labels'] = token_labels\n",
    "    x['token_length'] = len(token_labels)\n",
    "    return x\n",
    "\n",
    "# 한글이 포함되지 않는 Entity의 오류를 수정하는 함수\n",
    "def fix_label(x):\n",
    "    tokens = x['tokens']\n",
    "    labels = x['token_labels']\n",
    "\n",
    "    # 한글이 포함되지 않는 Entity 리스트\n",
    "    cat_list_nonkor = ['B-BANK_ACCOUNT', 'B-CELL_PHONE', 'B-CREDIT_CARD', 'B-DRIVER_LICENSE', 'B-EMAIL', 'B-PASSPORT', 'B-PHONE', 'B-RRN', 'B-SNS', 'I-BANK_ACCOUNT', 'I-CELL_PHONE', 'I-CREDIT_CARD', 'I-DRIVER_LICENSE', 'I-EMAIL', 'I-PASSPORT', 'I-PHONE', 'I-RRN', 'I-SNS']\n",
    "    korean_pattern = re.compile(r'[가-힣]') # 한글 포함 여부를 확인하는 정규표현식\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        token = tokens[i+1]\n",
    "        label = labels[i]\n",
    "\n",
    "        if label in cat_list_nonkor and bool(korean_pattern.search(token)):\n",
    "            x['token_labels'][i] = '0'\n",
    "        else:\n",
    "            x['token_labels'][i] = label\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se062Ey76HWa"
   },
   "source": [
    "label 정렬/수정 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgEEk61pisEf"
   },
   "outputs": [],
   "source": [
    "rds = [allign_tokens(item) for item in tqdm(the_new_data)]\n",
    "tds = [fix_label(item) for item in tqdm(rds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVL6T71L6JD7"
   },
   "source": [
    "데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JEOFfUAitlB"
   },
   "outputs": [],
   "source": [
    "idx = 67\n",
    "print(tds[idx]['text'])\n",
    "for i in range(len(tds[idx]['tokens'])):\n",
    "\n",
    "    try:\n",
    "        a = the_new_data[idx]['tokens'][i]\n",
    "        b = the_new_data[idx]['token_labels'][i-1]\n",
    "\n",
    "    # if b != '0':\n",
    "        print(f'{i}:{a}:{b}')\n",
    "    except Exception as e:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QS_kBaF6buk"
   },
   "source": [
    "label 추가 수정\n",
    "- 스페셜 토큰([CLS],[SEP])의 label을 -100으로 처리\n",
    "- 스페셜 토큰은 각각 토크나이징된 데이터의 가장 첫번째, 가장 마지막에 위치 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX9vm8-3ivxR"
   },
   "outputs": [],
   "source": [
    "def add_labels(x):\n",
    "    token_labels = x['token_labels']\n",
    "\n",
    "    labels = [-100] # [CLS] 토큰 label\n",
    "    for lab in token_labels:\n",
    "        idx = cat_idx_dict[lab]\n",
    "        labels.append(idx)\n",
    "\n",
    "    labels.append(-100) # [SEP] 토큰 label 처리\n",
    "    labels = np.array(labels)\n",
    "    x['labels'] = labels\n",
    "    return x\n",
    "\n",
    "# 함수 실행\n",
    "lds = [add_labels(item) for item in tds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVEfmywv7u05"
   },
   "source": [
    "데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lwTHxrfi1iU"
   },
   "outputs": [],
   "source": [
    "# idx = 67\n",
    "\n",
    "r_idx = random.choice(range(1990))\n",
    "print(lds[r_idx]['text'])\n",
    "for i in range(len(lds[r_idx]['tokens'])):\n",
    "\n",
    "    try:\n",
    "        a = lds[r_idx]['tokens'][i]\n",
    "        b = lds[r_idx]['labels'][i]\n",
    "\n",
    "    # if b != '0':\n",
    "        print(f'{i}:{a}:{b}')\n",
    "    except Exception as e:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFogCCfh71zm"
   },
   "source": [
    "## 데이터 임베딩\n",
    "> 앞서 전처리한 데이터를 Dataset 형식으로 변환하고 train, valid, test로 분할\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ERXa2S_8S5R"
   },
   "source": [
    "### Dataset 형식으로 변환\n",
    "- hugging face의 datasets 라이브러리\n",
    "- train set, validation set, test set으로 데이터 split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn8hy9NCi2pV"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "ds = Dataset.from_list(lds)\n",
    "\n",
    "# 데이터 split\n",
    "sds = ds.train_test_split(0.2)\n",
    "ssds = sds['test'].train_test_split(0.5)\n",
    "sds['valid'], sds['test'] = ssds['train'], ssds['test']\n",
    "\n",
    "# 데이터 분할 확인\n",
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDHVXB6787e4"
   },
   "source": [
    "### 학습 모델(토크나이저) 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZOejrjwi-zV"
   },
   "outputs": [],
   "source": [
    "# 학습 모델 id (hugging face model ID)\n",
    "model_path = 'klue/roberta-small'\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 모델 로드\n",
    "num_labels=len(cat_idx_dict) # 모델이 분류하는 entity의 수(갯수)를 정의\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "\n",
    "# 모델의 토큰 임베딩 크기를 토크나이저의 크기로 조정\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Oixk8459sS6"
   },
   "source": [
    "데이터 인코딩 함수\n",
    "- batch 처리 옵션을 적용 : truncation, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqYv6_X_jBAr"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oI3BC_sxjE5F"
   },
   "outputs": [],
   "source": [
    "# labels 패딩 함수\n",
    "def pad_labels(data):\n",
    "    seq_length = data['input_ids'].size(0)\n",
    "\n",
    "    # labels 텐서의 길이를 가져옵니다.\n",
    "    labels_length = data['labels'].size(0)\n",
    "\n",
    "    # labels 텐서를 input_ids의 길이와 동일하게 패딩합니다.\n",
    "    if labels_length < seq_length:\n",
    "        padding_length = seq_length - labels_length\n",
    "        padding_tensor = torch.full((padding_length,), -100, dtype=torch.long)\n",
    "        data['labels'] = torch.cat([data['labels'], padding_tensor])\n",
    "\n",
    "    # for k, v in data.items():\n",
    "    #     data[k] = v.unsqueeze(0)\n",
    "    return data\n",
    "\n",
    "def adjust_labels_length(data):\n",
    "    # input_ids의 tensor 길이 (sequence length).\n",
    "    seq_length = data['input_ids'].size(0)\n",
    "\n",
    "    # labels의 tensor 길이.\n",
    "    labels_length = data['labels'].size(0)\n",
    "\n",
    "    # tensor 길이 조정\n",
    "    if labels_length > seq_length:\n",
    "        data['labels'] = data['labels'][:seq_length]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVlg4Xhe-42e"
   },
   "source": [
    "### 데이터 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9UFb38u-_R8"
   },
   "source": [
    "토크나이징 함수 적용\n",
    "- torch 포맷으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCGh3KC8jGNa"
   },
   "outputs": [],
   "source": [
    "ds_enc = sds.map(tokenize_and_encode, batched=True)\n",
    "ds_enc.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeTNeWgb_J_o"
   },
   "source": [
    "데이터별 길이 맞춤(tensor 길이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry9qQRdajHcF"
   },
   "outputs": [],
   "source": [
    "ds_enc = ds_enc.map(pad_labels, num_proc=8, batched=False)\n",
    "ds_enc = ds_enc.map(adjust_labels_length, num_proc=8, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THuzg-GQ_T_3"
   },
   "source": [
    "## NER 모델 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO1apKMM_W_d"
   },
   "source": [
    "### Train augment 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3vc6hltjg0f"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3 # Epochs 설정\n",
    "project_name = f'NER_{EPOCHS}epochs' # 학습 실험 프로젝트 명명\n",
    "output_dir = f'./project/{project_name}' # 모델 저장경로 설정\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir, # 모델 저장 경로\n",
    "    num_train_epochs=EPOCHS, # 학습 Epochs\n",
    "    per_device_train_batch_size=4, # 학습 batch size\n",
    "    per_device_eval_batch_size=4, # 검증 batch size\n",
    "    warmup_steps=200, # warmup_steps\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy=\"epoch\", # 학습 중, 성능 평가 실행 기준\n",
    "    load_best_model_at_end=True, # 학습 모델(checkpoint) 저장 옵션 / 학습이 끝난 후 가장 좋은 모델 로드\n",
    "    metric_for_best_model=\"eval_loss\", # 가장 좋은 모델을 결정할 metric 기준\n",
    "    lr_scheduler_type=\"cosine_with_restarts\", # scheduler 설정\n",
    "    greater_is_better=False, # 모델 저장 기준의 모니터링 방향. 점수 정렬 기준\n",
    "    save_strategy='epoch', # 학습 모델(checkpoint) 저장 단위\n",
    "    save_total_limit=1, # 저장할 학습 모델(checkpoint) 개수\n",
    "\n",
    "    eval_strategy='epoch',  # Evaluation 실행 기준\n",
    "    logging_steps=10, # 학습 중 성능 지표 출력 기준\n",
    "    disable_tqdm=False, # 학습 진행률 표시 여부\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnpkBUEf_k6U"
   },
   "source": [
    "### 성능 지표(benchmark) 산출 함수\n",
    "- metric : accuracy, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ib3eP3Hl_fkh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def ner_compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # 패딩이나 특별 토큰이 아닌 경우에 대한 실제 레이블 및 예측값 추출\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for label_list, prediction in zip(labels, predictions):\n",
    "        for label, pred in zip(label_list, prediction):\n",
    "            # 무시할 토큰이 아니라면 리스트에 추가\n",
    "            if label != -100:  # 여기서 -100은 무시해야 할 레이블 ID입니다.\n",
    "                true_labels.append(label)\n",
    "                pred_labels.append(pred)\n",
    "\n",
    "    # 토큰 수준에서의 정확도 및 F1 점수 계산\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels, average='micro')  # NER에서는 'micro' 평균을 사용하는 것이 일반적입니다.\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6TDGrp5B8Go"
   },
   "source": [
    "### trainer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UL_lAJxMB7uA"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, # 학습 모델\n",
    "                  args=training_args, # train augments\n",
    "                  train_dataset=ds_enc[\"train\"], # 학습 데이터셋\n",
    "                  eval_dataset=ds_enc[\"valid\"], # 평가 데이터셋\n",
    "                  tokenizer=tokenizer, # 토크나이저\n",
    "                  compute_metrics=ner_compute_metrics # 성능 측정 함수\n",
    "                  )\n",
    "\n",
    "print(f'project : {project_name}')\n",
    "print(f'output_dir : {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLcaRUBVCciw"
   },
   "source": [
    "### NER 학습 실행\n",
    "- training_args 등에서 설정한 hyper parameter로 학습을 실행\n",
    "- epoch 단위 성능 평가 실행\n",
    "- 학습 완료 후, best model에 해당하는 checkpoint와 tokenizer 저장\n",
    "    - checkpoint 1개 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doriyYu8j0cl"
   },
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print(f'project : {project_name}')\n",
    "\n",
    "# 학습 실행(trainer)\n",
    "trainer.train()\n",
    "\n",
    "# 토크나이저 저장(학습 완료 후, 모델의 저장 경로를 확인하여 저장)\n",
    "tokenizer_path = glob.glob(os.path.join(training_args.output_dir,'*'))\n",
    "print(tokenizer_path)\n",
    "tokenizer.save_pretrained(tokenizer_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxqaAKHnLpx3"
   },
   "source": [
    "## 성능 측정\n",
    "> 학습한 모델의 benchmark와 추론 테스트를 통해 성능을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXCLgcycL1PM"
   },
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMvxv1EFj2se"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEEh0LPlM7ee"
   },
   "source": [
    "### 학습 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVyVkMlKM79t"
   },
   "outputs": [],
   "source": [
    "# 학습 모델(checkpoint) 경로\n",
    "ckp_model='./project/NER_3epochs/checkpoint-798'\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckp_model)\n",
    "\n",
    "# 모델 로드\n",
    "model = AutoModelForTokenClassification.from_pretrained(ckp_model, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPPu4_UEML0K"
   },
   "source": [
    "### benchmark 측정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9WzRd66Mhsv"
   },
   "source": [
    "benchmark 측정 함수\n",
    "- accuracy와 f1 score를 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJYPE3Fgj7NZ"
   },
   "outputs": [],
   "source": [
    "# benchmark 함수\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "def ner_compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # 패딩이나 특별 토큰이 아닌 경우에 대한 실제 레이블 및 예측값 추출\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for label_list, prediction in zip(labels, predictions):\n",
    "        for label, pred in zip(label_list, prediction):\n",
    "            # 무시할 토큰이 아니라면 리스트에 추가\n",
    "            if label != -100:  # 여기서 -100은 무시해야 할 레이블 ID입니다.\n",
    "                true_labels.append(label)\n",
    "                pred_labels.append(pred)\n",
    "\n",
    "    # 토큰 수준에서의 정확도 및 F1 점수 계산\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels, average='micro')  # NER에서는 'micro' 평균을 사용하는 것이 일반적입니다.\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgSXK_LgMoVr"
   },
   "source": [
    "Benchmark Augmemnt 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDbnFnVzj7Ph"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    'eval',\n",
    "    fp16=True,\n",
    "    report_to='none',\n",
    "    per_device_eval_batch_size=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXhWiTpmmisK"
   },
   "source": [
    "benchmark trainer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foxK2ifLmjea"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=ner_compute_metrics\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdsVmrQmN7vC"
   },
   "source": [
    "benchmark 실행 & 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfUBuoVHj7Rn"
   },
   "outputs": [],
   "source": [
    "# benchmark 데이터셋\n",
    "test_data = ds_enc['test']\n",
    "\n",
    "# benchmark 실행\n",
    "benchmark_result = trainer.predict(test_data)\n",
    "\n",
    "# benchmark 결과 확인\n",
    "benchmark_result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GWXlXYwOGQc"
   },
   "source": [
    "### 모델 추론 테스트 (pipeline)\n",
    "> 학습한 모델을 NER 파이프라인으로 로드하여 텍스트 입력에 대한 결과를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xl4F1cqLOO8d"
   },
   "source": [
    "### NER 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70hQEcltOygJ"
   },
   "source": [
    "파이프라인 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjbRSA04kiAs"
   },
   "outputs": [],
   "source": [
    "# 테스트 텍스트 -> 개인정보가 포함된 텍스트\n",
    "original_text=test_data[3]['text']\n",
    "\n",
    "# NER 파이프라인 실행\n",
    "ner = pipeline(\"ner\", model=ckp_model, tokenizer=tokenizer, grouped_entities=True,device=0)# 파이프라인 입력\n",
    "\n",
    "# NER 파이프라인 실행\n",
    "result = ner(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7DxaVVzPhmE"
   },
   "source": [
    "NER 결과 확인\n",
    "- NER 모델의 결과는 entity_group, score, word, start, end 로 구성 됨\n",
    "    - entity_group : Entity label\n",
    "    - score : Entity 추론 점수\n",
    "    - word : 객체 텍스트\n",
    "    - start : word의 시작 index\n",
    "    - end : word의 종료 index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWMxM_BgkjcB"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cM_xu-YiQ7Jm"
   },
   "source": [
    "## 개인정보 비식별화 처리\n",
    "> 텍스트(개인정보가 포함된 텍스트)를 파이프라인으로 불러온 NER 모델에 입력하여 개인정보가 비식별화 처리된 텍스트를 반환하는 프로세스를 구축\n",
    "- entity_group을 Entity 객체로 다시 매핑 (LABEL_1 -> ADDRESS)\n",
    "- 'B-', 'I-'로 나눠진 Entity는 병합하여 하나의 객체로 처리\n",
    "- 의미없는 Entity(LABEL_0,0)은 출력되지 않도록 함.\n",
    "- 병합 처리된 entity_group, word, index(strart,end)를 기준으로 텍스트(개인정보가 포함된 텍스트)의 가명처리(비식별화)를 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrUIo373S8bB"
   },
   "source": [
    "### NER(pipeline) 결과 처리 함수\n",
    "- postprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjBwxCL0kkv9"
   },
   "outputs": [],
   "source": [
    "# 라벨을 카테고리로 매핑하는 함수\n",
    "cat_list = list(cat_idx_dict.keys())\n",
    "\n",
    "# entity_group 라벨을 entity 명으로 변환하는 함수\n",
    "def label_changer(x,origin_text):\n",
    "    result_list = []\n",
    "    for item in x:\n",
    "\n",
    "        # entity_group이 LABEL_0이 아닌 값만 추출\n",
    "        if item['entity_group'] != 'LABEL_0':\n",
    "            label_num = int(item['entity_group'].split('_')[-1])\n",
    "\n",
    "            # category list에서 LABEL에 맞는 값을 찾아 치환\n",
    "            entity_group = cat_list[label_num]\n",
    "\n",
    "            # 치환한 LABEL, 입력된 텍스트에서 추출된 단어, 단어의 위치 값으로 dict 저장\n",
    "            data_dict = {\n",
    "                'entity_group':entity_group,\n",
    "                'word':origin_text[item['start']:item['end']],\n",
    "                'location':[item['start'],item['end']]\n",
    "            }\n",
    "\n",
    "            result_list.append(data_dict)\n",
    "\n",
    "    return result_list\n",
    "\n",
    "# BIO 표기로 나눠진 entity_group 병합 함수\n",
    "def predict_printer(x):\n",
    "    merged_results = []\n",
    "    current_entity = None\n",
    "    current_word = ''\n",
    "    current_location = []\n",
    "\n",
    "    for item in x:\n",
    "        entity_group = item['entity_group']\n",
    "        word = item['word']\n",
    "        location = item['location']\n",
    "\n",
    "        if entity_group.startswith('B-'):\n",
    "            if current_entity:\n",
    "                # 이전 결과 추가\n",
    "                merged_results.append({\n",
    "                    'entity_group': current_entity[2:],  # 'B-' 제거\n",
    "                    'word': current_word,\n",
    "                    'location': [current_location[0], current_location[1]]  # 시작과 끝 위치\n",
    "                })\n",
    "\n",
    "            # 새 엔티티 시작\n",
    "            current_entity = entity_group\n",
    "            current_word = word\n",
    "            current_location = location\n",
    "        elif entity_group.startswith('I-') and current_entity and entity_group[2:] == current_entity[2:]:\n",
    "            # 같은 엔티티 그룹의 I-일 경우 병합\n",
    "            current_word += word\n",
    "            current_location[1] = location[1]  # 끝 위치 업데이트\n",
    "\n",
    "    # 마지막 엔티티 결과 추가\n",
    "    if current_entity:\n",
    "        merged_results.append({\n",
    "            'entity_group': current_entity[2:],  # 'B-' 제거\n",
    "            'word': current_word,\n",
    "            'location': [current_location[0], current_location[1]]\n",
    "        })\n",
    "\n",
    "    return merged_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdvD2woGTVzi"
   },
   "source": [
    "NER postprocess 함수 테스트\n",
    "- 'B-', 'I-'로 구분된 객체명의 병합을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZGRKMXnkqzK"
   },
   "outputs": [],
   "source": [
    "result = ner(original_text)\n",
    "\n",
    "print('\\n')\n",
    "print('+++++++++++++++++\\n')\n",
    "print('### 텍스트 ###')\n",
    "print(original_text)\n",
    "ner_result = label_changer(result,original_text)\n",
    "ner_result = predict_printer(ner_result)\n",
    "\n",
    "ner_result\n",
    "\n",
    "print(ner_result)\n",
    "print('\\n+++++++++++++++++\\n')\n",
    "print('### NER ###')\n",
    "for item in ner_result:\n",
    "    print(item['entity_group'],':',item['word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pb0pkm3_U2rN"
   },
   "source": [
    "### 텍스트 가명처리 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4s37CWzmCzd"
   },
   "outputs": [],
   "source": [
    "target_text = original_text  # 변환 텍스트\n",
    "\n",
    "# 역순 정렬로 대체: 위치 겹침 방지\n",
    "for entity in sorted(ner_result, key=lambda x: x['location'][0], reverse=True):\n",
    "    category = entity['entity_group']\n",
    "    location = entity['location']\n",
    "    word = target_text[location[0]:location[1]]\n",
    "    entity['word'] = word  # 병합된 word 값 사용\n",
    "    target_text = target_text[:location[0]] + f'#@{category}#' + target_text[location[1]:]\n",
    "\n",
    "data_dict = {\n",
    "    'text': original_text,\n",
    "    'prediction': ner_result,\n",
    "    'de_identification_text': target_text\n",
    "}\n",
    "\n",
    "print(data_dict['de_identification_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDoQVcFWU--e"
   },
   "source": [
    "### 개인정보 가명처리 코드(for 문)\n",
    "- 테스트 데이터의 text를 순회하며 개인정보 가명처리를 적용\n",
    "- 최종적으로 출력되는 데이터 입력되는 텍스트, 가명처리 정보, 가명처리된 텍스트로 구성\n",
    "    - text : 입력 텍스트\n",
    "    - prediction : 가명처리 정보(전처리된 모델의 추론결과)\n",
    "    - de_identification_text : 가명처리된 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPd_wGianugE"
   },
   "outputs": [],
   "source": [
    "test_data = ds_enc['test']\n",
    "\n",
    "ner_results = []\n",
    "\n",
    "for item in tqdm(test_data):\n",
    "    original_text = item['text']\n",
    "    result = ner(original_text)\n",
    "    ner_result = label_changer(result,original_text)\n",
    "    ner_result = predict_printer(ner_result)\n",
    "    # print(ner_result)\n",
    "\n",
    "    target_text = original_text  # 변환 텍스트\n",
    "\n",
    "    # 역순 정렬로 대체: 위치 겹침 방지\n",
    "    for entity in sorted(ner_result, key=lambda x: x['location'][0], reverse=True):\n",
    "        category = entity['entity_group']\n",
    "        location = entity['location']\n",
    "\n",
    "        word = target_text[location[0]:location[1]] # 텍스트 파싱(index 기준)\n",
    "        entity['word'] = word  # 병합된 word 값 사용\n",
    "        target_text = target_text[:location[0]] + f'#@{category}#' + target_text[location[1]:]\n",
    "\n",
    "    data_dict = {\n",
    "        'text': original_text,\n",
    "        'prediction': ner_result,\n",
    "        'de_identification_text': target_text\n",
    "    }\n",
    "\n",
    "    ner_results.append(data_dict)\n",
    "\n",
    "print(len(ner_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ec07QAHXWZ04"
   },
   "source": [
    "### 가명처리 결과 확인\n",
    "- Dataframe(pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcQM7FxtUmwe"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ner_results)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4p5Rkp_-U2ZL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
